{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Setup\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather dataset and preprocess (Ashley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Answer</th>\n",
       "      <th>num_of_lines</th>\n",
       "      <th>code_length</th>\n",
       "      <th>comments</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>num_of_indents</th>\n",
       "      <th>loop_count</th>\n",
       "      <th>line_length</th>\n",
       "      <th>identifiers</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>class Solution {\\r\\n public:\\r\\n  vector&lt;int&gt; ...</td>\n",
       "      <td>8</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>43.375000</td>\n",
       "      <td>8</td>\n",
       "      <td>4.996250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>class Solution {\\r\\n public:\\r\\n  ListNode* ad...</td>\n",
       "      <td>12</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>39.916667</td>\n",
       "      <td>2</td>\n",
       "      <td>5.727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>class Solution {\\r\\n public:\\r\\n  int lengthOf...</td>\n",
       "      <td>9</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>6.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>class Solution {\\r\\n public:\\r\\n  double findM...</td>\n",
       "      <td>16</td>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65.375000</td>\n",
       "      <td>22</td>\n",
       "      <td>1.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>class Solution {\\r\\n public:\\r\\n  string longe...</td>\n",
       "      <td>14</td>\n",
       "      <td>916</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>65.428571</td>\n",
       "      <td>14</td>\n",
       "      <td>2.051429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Answer  \\\n",
       "0           0  class Solution {\\r\\n public:\\r\\n  vector<int> ...   \n",
       "1           1  class Solution {\\r\\n public:\\r\\n  ListNode* ad...   \n",
       "2           2  class Solution {\\r\\n public:\\r\\n  int lengthOf...   \n",
       "3           3  class Solution {\\r\\n public:\\r\\n  double findM...   \n",
       "4           4  class Solution {\\r\\n public:\\r\\n  string longe...   \n",
       "\n",
       "   num_of_lines  code_length  comments  cyclomatic_complexity  num_of_indents  \\\n",
       "0             8          347         0                      1               4   \n",
       "1            12          479         0                      3               5   \n",
       "2             9          303         0                      2               3   \n",
       "3            16         1046         0                      4               3   \n",
       "4            14          916         3                      4               9   \n",
       "\n",
       "   loop_count  line_length  identifiers  readability  \n",
       "0           2    43.375000            8     4.996250  \n",
       "1           3    39.916667            2     5.727500  \n",
       "2           2    33.666667            6     6.070000  \n",
       "3           4    65.375000           22     1.496250  \n",
       "4           7    65.428571           14     2.051429  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_cpp.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "prompt = \"{ Please fill in this function }\"\n",
    "\n",
    "def emptyOneFunctionBody(code, firstBrace):\n",
    "    # Find corresponding }\n",
    "    numBraces = 1\n",
    "    i = firstBrace + 1\n",
    "\n",
    "    # print(\"------------------------------------------\\n Code before Mod:\\n\" + code)\n",
    "    # print(i)\n",
    "    # print(\"Character found prior to firstBrace: $\" + code[i-1] +  code[i] + code[i+1] + \"$\")\n",
    "\n",
    "    while i < len(code) and numBraces > 0:\n",
    "        if code[i] == '{':\n",
    "            numBraces += 1\n",
    "        elif code[i] == '}':\n",
    "            numBraces -= 1\n",
    "        i += 1\n",
    "    \n",
    "    # print(\"Character found after lastBrace: $\" + code[i-1] +  code[i]+ \"$\\n------------------------------------------\\n\")\n",
    "    return code[:firstBrace] + prompt + code[i:], firstBrace + len(prompt)\n",
    "    \n",
    "\n",
    "def emptyAllFunctionBodies(code, start):\n",
    "    # Find first { after first )\n",
    "    start = max(code.find(')'), start)\n",
    "    if start < 0:\n",
    "        return code\n",
    "    else:\n",
    "        openBraceLocation = code.find('{', start)\n",
    "        if openBraceLocation == -1:\n",
    "            return code\n",
    "        else:\n",
    "            newCode, newStart = emptyOneFunctionBody(code, openBraceLocation)\n",
    "            return emptyAllFunctionBodies(newCode, newStart)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "class Solution {\n",
      " public:\n",
      "  vector<vector<string>> solveNQueens(int n) {\n",
      "    vector<vector<string>> ans;\n",
      "    dfs(n, 0, vector<bool>(n), vector<bool>(2 * n - 1), vector<bool>(2 * n - 1),\n",
      "        vector<string>(n, string(n, '.')), ans);\n",
      "    return ans;\n",
      "  }\n",
      "\n",
      " private:\n",
      "  void dfs(int n, int i, vector<bool>&& cols, vector<bool>&& diag1,\n",
      "           vector<bool>&& diag2, vector<string>&& board,\n",
      "           vector<vector<string>>& ans) {\n",
      "    if (i == n) {\n",
      "      ans.push_back(board);\n",
      "      return;\n",
      "    }\n",
      "\n",
      "    for (int j = 0; j < n; ++j) {\n",
      "      if (cols[j] || diag1[i + j] || diag2[j - i + n - 1])\n",
      "        continue;\n",
      "      board[i][j] = 'Q';\n",
      "      cols[j] = diag1[i + j] = diag2[j - i + n - 1] = true;\n",
      "      dfs(n, i + 1, move(cols), move(diag1), move(diag2), move(board), ans);\n",
      "      cols[j] = diag1[i + j] = diag2[j - i + n - 1] = false;\n",
      "      board[i][j] = '.';\n",
      "    }\n",
      "  }\n",
      "};\n",
      "\n",
      "class Solution {\n",
      " public:\n",
      "  vector<vector<string>> solveNQueens(int n) { Please fill in this function }\n",
      "\n",
      " private:\n",
      "  void dfs(int n, int i, vector<bool>&& cols, vector<bool>&& diag1,\n",
      "           vector<bool>&& diag2, vector<string>&& board,\n",
      "           vector<vector<string>>& ans) { Please fill in this function }\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "# Test function on one coding sample\n",
    "code_sample = data['Answer'][50]\n",
    "print(type(code_sample))\n",
    "print(code_sample + \"\\n\")\n",
    "code_sample = emptyAllFunctionBodies(code_sample, 0)\n",
    "print(code_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Solution {\n",
      " public:\n",
      "  vector<int> twoSum(vector<int>& nums, int target) {\n",
      "    unordered_map<int, int> numToIndex;\n",
      "\n",
      "    for (int i = 0; i < nums.size(); ++i) {\n",
      "      if (const auto it = numToIndex.find(target - nums[i]);\n",
      "          it != cend(numToIndex))\n",
      "        return {it->second, i};\n",
      "      numToIndex[nums[i]] = i;\n",
      "    }\n",
      "\n",
      "    throw;\n",
      "  }\n",
      "};\n",
      "-------------------------------------------------\n",
      "class Solution {\n",
      " public:\n",
      "  vector<int> twoSum(vector<int>& nums, int target) { Please fill in this function }\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "# Duplicate the column Answer\n",
    "data['Answer_empty'] = data['Answer']\n",
    "\n",
    "for i in range(17):\n",
    "    data.loc[i, 'Answer_empty'] = emptyAllFunctionBodies(data.loc[i, 'Answer'], 0)\n",
    "\n",
    "print(data['Answer'][0])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(data['Answer_empty'][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Take the emptied code and ask an LLM to fill in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a Run data generation (DONT DO THIS EVERY TIME RUN IT ONCE THEN STORE IT.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m genai\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m ai_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAnswer_empty\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))]\n\u001b[0;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai_generated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ai_values\n\u001b[0;32m      7\u001b[0m data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_cpp_human.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import time\n",
    "\n",
    "ai_values = [0 for i in range(len(data['Answer_empty']))]\n",
    "data['ai_generated'] = ai_values\n",
    "\n",
    "data.to_csv('data_cpp_human.csv', index=False)\n",
    "\n",
    "# create a dummy dataframe to store the AI generated code until we concatenate w/ original dataframe\n",
    "ai_data = pd.DataFrame(columns = data.columns)\n",
    "\n",
    "# USE YOUR OWN API TOKEN/KEY HERE for API access, we're using Gemini 2.0 Flash model\n",
    "client = genai.Client(api_key=\"PUT_API_TOKEN_HERE\")\n",
    "\n",
    "# This is the number of requests you can make per minute, adjust as needed\n",
    "requests_per_minute = 15\n",
    "\n",
    "## Loop through the data and generate AI code wherever it says \"Please fill in this function\".\n",
    "for i,code in enumerate(data['Answer_empty']):\n",
    "    request = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", contents=\"In the following code snippet, give the C++ implementation where it says \\\"Please fill in this function\\\" in the appropriate C++ implementation. Do not generate additional text.\\n\" + data['Answer_empty'][0],\n",
    "    )\n",
    "    ## check if it included markdown syntax\n",
    "    generated_code = request.text\n",
    "    if \"```cpp\" in generated_code:\n",
    "        generated_code = generated_code.split(\"```cpp\")[1].split(\"```\")[0]\n",
    "\n",
    "    response = code.replace(\"Please fill in this function\", generated_code)\n",
    "    \n",
    "    ## Calculate the number of lines, code length, comments, num of indents, loop count, avg line length, identifiers, readability\n",
    "    num_of_lines = len(response.split(\"\\n\"))\n",
    "    code_length = len(response)\n",
    "    comments = len(re.findall(r'//', response)) + (len(re.findall(r'/\\*', response)) + len(re.findall(r'\\*/', response))) // 2\n",
    "    num_indents = len(re.findall(r'\\t', response)) + len(re.findall(r'    ', response))\n",
    "    loop_count = len(re.findall(r'for', response)) + len(re.findall(r'while', response))\n",
    "    avg_line_length = code_length / num_of_lines\n",
    "    identifiers = len(re.findall(r'\\b\\w+\\b', response)) / num_of_lines\n",
    "    readability = 0.39 * avg_line_length + 0.1 * num_indents + 0.15 * comments + 0.2 * loop_count + 0.16 * identifiers\n",
    "    \n",
    "    ## put the data in a new row, and append it to the dummy dataframe\n",
    "    new_row = [i, response, num_of_lines,  code_length,  comments, 0, num_indents,  loop_count,  avg_line_length,  identifiers, readability, None, 1]\n",
    "    ai_data = pd.concat([ai_data, pd.DataFrame([new_row], columns=ai_data.columns)], ignore_index=True)\n",
    "    time.sleep(60 / requests_per_minute * 1.1)\n",
    "\n",
    "ai_data.to_csv('data_cpp_ai.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b After you have generated AI code data, read it and merge with human sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try to read the data from the csv file, if it exists\n",
    "try:\n",
    "    data_ai = pd.read_csv('data_cpp_ai.csv')\n",
    "    data_human = pd.read_csv('data_cpp.csv')\n",
    "except:\n",
    "    print(\"One or more data files not found. Please make sure the data file is in the same directory as this script. or run the data generation script first.\")\n",
    "    ## create a new column to store the AI generated code, initialize existing code as human generated\n",
    "## initialize the \n",
    "data_human['ai_generated'] = 0\n",
    "\n",
    "data_human.to_csv('data_cpp_human.csv', index=False)\n",
    "\n",
    "## drop weird indexing column and intermediate column for empty function headers\n",
    "data_ai.drop(columns=['Unnamed: 0', \"Answer_empty\"], inplace=True)\n",
    "## drop weird indexing column\n",
    "data_human.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "data_combined = pd.concat([data_human, data_ai], ignore_index=True)\n",
    "\n",
    "## saved the combined data to a file so we don't have to redo this entire process again\n",
    "data_combined.to_csv('data_cpp_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use a large codebase repository to train a Doc2Vec model to be used in converting programming language code into a vector embedding for the model\n",
    "\n",
    "In order to avoid the issue of giving the model code with sections/ngrams that it hasn't seen before, you would want to train it on a sufficiently large corpus of potential text to capture data beyond your dataset.\n",
    "In our case, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Create corpus from code samples\n",
    "documents = data_combined['Answer']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encode code samples into vector embeddings and construct the data table to be passed to the model.\n",
    "\n",
    "Alternative idea, use the new Google Gemini API based embedding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenize all code (Word2Vec) and create features for our ML model to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run ML models (ex: Random Forest (RF), XGBoost, and Support Vector Machine (SVM) ) (Muntaka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace this data with actual data\n",
    "data = {\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.rand(100),\n",
    "    'Target': np.random.choice([0, 1], size=100) \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Feature1', 'Feature2']]\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_preds = rf_model.predict(X_test_scaled)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test_scaled)\n",
    "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
    "print(f\"XGBoost Accuracy: {xgb_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_preds = svm_model.predict(X_test_scaled)\n",
    "svm_acc = accuracy_score(y_test, svm_preds)\n",
    "print(f\"SVM Accuracy: {svm_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gather precision, recall, accuracy, and f1-score for each model (Muntaka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds, average='binary')\n",
    "    recall = recall_score(y_test, preds, average='binary')\n",
    "    f1 = f1_score(y_test, preds, average='binary')\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc, rf_precision, rf_recall, rf_f1 = evaluate_model(rf_model, X_test_scaled, y_test)\n",
    "xgb_acc, xgb_precision, xgb_recall, xgb_f1 = evaluate_model(xgb_model, X_test_scaled, y_test)\n",
    "svm_acc, svm_precision, svm_recall, svm_f1 = evaluate_model(svm_model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    Recall  F1-Score\n",
       "0  Random Forest      0.50   0.555556  0.454545  0.500000\n",
       "1        XGBoost      0.35   0.375000  0.272727  0.315789\n",
       "2            SVM      0.55   0.583333  0.636364  0.608696"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\", \"XGBoost\", \"SVM\"],\n",
    "    \"Accuracy\": [rf_acc, xgb_acc, svm_acc],\n",
    "    \"Precision\": [rf_precision, xgb_precision, svm_precision],\n",
    "    \"Recall\": [rf_recall, xgb_recall, svm_recall],\n",
    "    \"F1-Score\": [rf_f1, xgb_f1, svm_f1]\n",
    "})\n",
    "\n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
